---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am Donghan Yu, a fourth-year Ph.D. student in Language Technologies Institute, Carnegie Mellon University. I am fortunately advised by Prof. [Yiming Yang](https://www.cs.cmu.edu/~./yiming/). Before that, I received my B.S. in Electronic Engineering from Tsinghua University, advised by Prof. [Yong Li](http://fi.ee.tsinghua.edu.cn/~liyong/). 

My research interests include knowledge-enhanced NLP, knowledge graph modeling and graph neural networks. My recent research experience covers (1) joint pretraining on knowledge graphs and texts, (2) knowledge graph enhanced open-domain question answering, (3) graph convolutional networks for knowledge graph modeling.

## Publications ##

1. [KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering](https://arxiv.org/abs/2110.04330)        
    **Donghan Yu**, Chenguang Zhu, Yuwei Fang, Wenhao Yu, Shuohang Wang, Yichong Xu, Xiang Ren, Yiming Yang, Michael Zeng     
    ACL 2022   

2. [Dict-BERT: Enhancing Language Model Pre-training with Dictionary](https://arxiv.org/abs/2110.06490)     
    Wenhao Yu, Chenguang Zhu, Yuwei Fang, **Donghan Yu**, Shuohang Wang, Yichong Xu, Michael Zeng, Meng Jiang     
    ACL 2022

